{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bb58342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled.shape: (62926, 82)\n",
      "y_train_scaled.shape: (62926, 63)\n"
     ]
    }
   ],
   "source": [
    "# データの準備\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # トレーニングデータ\n",
    "# data_pairs = [\n",
    "#     ('./data/20250518test3/Opti-track/3_final/Take 2024-11-15 03.19.59 PM.csv',\n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_152500_left.csv',\n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_152500_right.csv'),\n",
    "#     ('./data/20250518test3/Opti-track/3_final/Take 2024-11-15 03.26.00 PM.csv',\n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_153100_left.csv', \n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_153100_right.csv'),\n",
    "#     ('./data/20250518test3/Opti-track/3_final/Take 2024-11-15 03.31.59 PM.csv', \n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_153700_left.csv', \n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_153700_right.csv'),\n",
    "#     ('./data/20250518test3/Opti-track/3_final/Take 2024-11-15 03.37.59 PM.csv', \n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_154300_left.csv', \n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_154300_right.csv'),\n",
    "#     ('./data/20250518test3/Opti-track/3_final/Take 2024-11-15 03.43.59 PM.csv', \n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_154900_left.csv', \n",
    "#      './data/20250518test3/insoleSensor/3_final/20241115_154900_right.csv'),\n",
    "#     ('./data/20250518test4/Opti-track/3_final/Take 2024-12-12 03.06.59 PM.csv',\n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_152700_left.csv', \n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_152700_right.csv'),\n",
    "#     ('./data/20250518test4/Opti-track/3_final/Take 2024-12-12 03.45.00 PM.csv', \n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_160501_left.csv', \n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_160501_right.csv'),\n",
    "#     ('./data/20250518test4/Opti-track/3_final/Take 2024-12-12 04.28.00 PM.csv', \n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_164800_left.csv', \n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_164800_right.csv'),\n",
    "#     ('./data/20250518test4/Opti-track/3_final/Take 2024-12-12 05.17.59 PM.csv', \n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_173800_left.csv', \n",
    "#      './data/20250518test4/insoleSensor/3_final/20241212_173800_right.csv')\n",
    "# ]\n",
    "\n",
    "# # テストデータ\n",
    "# test_data = ('./data/20250518test3/Opti-track/3_final/Take 2024-11-15 03.49.59 PM.csv', \n",
    "#              './data/20250518test3/insoleSensor/3_final/20241115_155500_left.csv', \n",
    "#              './data/20250518test3/insoleSensor/3_final/20241115_155500_right.csv')\n",
    "\n",
    "data_pairs = [\n",
    "        #\n",
    "        # 第三回収集データ\n",
    "        #\n",
    "        # # 立ちっぱなし\n",
    "        ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.20.00 PM.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_152500_left.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_152500_right.csv'),\n",
    "        # お辞儀\n",
    "        ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.26.00 PM.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_153100_left.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_153100_right.csv'),\n",
    "        # 体の横の傾け\n",
    "        ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.32.00 PM.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_153700_left.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_153700_right.csv'),\n",
    "        # 立つ座る\n",
    "        ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.38.00 PM.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_154300_left.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_154300_right.csv'),\n",
    "        # スクワット\n",
    "        ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.44.00 PM.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_154900_left.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_154900_right.csv'),\n",
    "        # 総合(test3)\n",
    "        # ('./data/20241115test3/Opti-track/Take 2024-11-15 03.50.00 PM.csv',\n",
    "        # './data/20241115test3/insoleSensor/20241115_155500_left.csv', \n",
    "        # './data/20241115test3/insoleSensor/20241115_155500_right.csv'),\n",
    "\n",
    "        # 釘宮くん\n",
    "        ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 03.06.59 PM.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_152700_left.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_152700_right.csv'),\n",
    "        # 百田くん\n",
    "        ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 03.45.00 PM.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_160501_left.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_160501_right.csv'),\n",
    "        # # # # 渡辺(me)\n",
    "        ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 04.28.00 PM.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_164800_left.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_164800_right.csv'),\n",
    "        # にるぱむさん\n",
    "        ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 05.17.59 PM.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_173800_left.csv',\n",
    "         './data/20250517old_data/20241212test4/insoleSensor/20241212_173800_right.csv')\n",
    "    ]\n",
    "\n",
    "# # テストデータ\n",
    "# test_data = ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.50.00 PM.csv', \n",
    "#              './data/20250517old_data/20241115test3/insoleSensor/20241115_155500_left.csv', \n",
    "#              './data/20250517old_data/20241115test3/insoleSensor/20241115_155500_right.csv')\n",
    "\n",
    "test_data = ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.44.00 PM.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_154900_left.csv',\n",
    "         './data/20250517old_data/20241115test3/insoleSensor/20241115_154900_right.csv')\n",
    "\n",
    "# トレーニングデータを格納するリスト\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "for opti_path, left_path, right_path in data_pairs:\n",
    "    left_df = pd.read_csv(left_path)\n",
    "    right_df = pd.read_csv(right_path)\n",
    "    skeleton_df = pd.read_csv(opti_path)\n",
    "\n",
    "    left_df = left_df.fillna(0.0)\n",
    "    right_df = right_df.fillna(0.0)\n",
    "    skeleton_df = skeleton_df.fillna(0.0)\n",
    "\n",
    "    X = pd.concat([left_df, right_df], axis=1).values\n",
    "    y = skeleton_df.values\n",
    "\n",
    "    X_train_list.append(X)\n",
    "    y_train_list.append(y)\n",
    "\n",
    "# リスト内のデータを結合\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "\n",
    "# スケーリング\n",
    "x_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "\n",
    "\n",
    "print(\"X_train_scaled.shape:\", X_train_scaled.shape)\n",
    "print(\"y_train_scaled.shape:\", y_train_scaled.shape)\n",
    "\n",
    "\n",
    "# テストデータの読み込み\n",
    "opti_path_test, left_path_test, right_path_test = test_data\n",
    "left_df_test = pd.read_csv(left_path_test)\n",
    "right_df_test = pd.read_csv(right_path_test)\n",
    "skeleton_df_test = pd.read_csv(opti_path_test)\n",
    "\n",
    "left_df_test = left_df_test.fillna(0.0)\n",
    "right_df_test = right_df_test.fillna(0.0)\n",
    "skeleton_df_test = skeleton_df_test.fillna(0.0)\n",
    "\n",
    "X_test = pd.concat([left_df_test, right_df_test], axis=1).values\n",
    "y_test = skeleton_df_test.values\n",
    "\n",
    "# スケーリング (トレーニングデータでfitしたスケーラーを使用)\n",
    "X_test_scaled = x_scaler.transform(X_test)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "996abee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DetasetとDataLoaderの定義\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def create_sliding_window_sequences(X, y, window_size):\n",
    "    X_seq, y_seq, mask_seq = [], [], []\n",
    "    for i in range(len(X) - window_size + 1):\n",
    "        x_window = X[i:i+window_size]\n",
    "        y_window = y[i+window_size-1]  # 未来1ステップの姿勢など\n",
    "        mask_window = (x_window.sum(axis=1) != 0).astype(int)  # 欠損でないとき1\n",
    "\n",
    "        X_seq.append(x_window)\n",
    "        y_seq.append(y_window)\n",
    "        mask_seq.append(mask_window)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq), np.array(mask_seq)\n",
    "\n",
    "# 適用例\n",
    "window_size = 10\n",
    "X_seq_train, y_seq_train, mask_seq_train = create_sliding_window_sequences(X_train_scaled, y_train_scaled, window_size)\n",
    "X_seq_test, y_seq_test, mask_seq_test = create_sliding_window_sequences(X_test_scaled, y_test_scaled, window_size)\n",
    "\n",
    "class PostureDataset(Dataset):\n",
    "    def __init__(self, X_seq, y_seq, mask_seq):\n",
    "        self.X = torch.tensor(X_seq, dtype=torch.float32)      # [B, S, D]\n",
    "        self.y = torch.tensor(y_seq, dtype=torch.float32)      # [B, out_dim]\n",
    "        self.mask = torch.tensor(mask_seq, dtype=torch.long)   # [B, S]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.mask[idx]\n",
    "\n",
    "\n",
    "train_dataset = PostureDataset(X_seq_train, y_seq_train, mask_seq_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = PostureDataset(X_seq_test, y_seq_test, mask_seq_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# バリデーションデータの DataLoader は不要になるので削除またはコメントアウト\n",
    "# val_dataset = PostureDataset(X_val, y_val)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ada49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertConfig\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "\n",
    "class TimeSeriesBERTRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=63, hidden_dim=256, dropout=0.1):\n",
    "        super(TimeSeriesBERTRegressor, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        config = BertConfig(\n",
    "            hidden_size=hidden_dim,\n",
    "            num_attention_heads=8,\n",
    "            num_hidden_layers=4,\n",
    "            intermediate_size=hidden_dim * 4,\n",
    "            hidden_dropout_prob=dropout,\n",
    "            attention_probs_dropout_prob=dropout\n",
    "        )\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, attention_mask):\n",
    "        # x: [B, S, input_dim] → [B, S, hidden_dim]\n",
    "        x = self.embedding(x)\n",
    "        outputs = self.bert(inputs_embeds=x, attention_mask=attention_mask)\n",
    "        \n",
    "        # 代表特徴（例: 最後のトークン）\n",
    "        last_hidden = outputs.last_hidden_state  # [B, S, H]\n",
    "        cls_rep = last_hidden[:, -1, :]  # or mean-pooling if desired\n",
    "        \n",
    "        return self.regressor(cls_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00bec43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル・損失関数・最適化の定義\n",
    "model = TimeSeriesBERTRegressor(input_dim=82, output_dim=63)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05b16241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 1967/1967 [00:17<00:00, 113.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] - Train Loss: 0.3789\n",
      "             Validation Loss: 0.3993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 1967/1967 [00:17<00:00, 112.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30] - Train Loss: 0.2162\n",
      "             Validation Loss: 0.3070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 1967/1967 [00:17<00:00, 110.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30] - Train Loss: 0.1727\n",
      "             Validation Loss: 0.3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 1967/1967 [00:42<00:00, 46.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30] - Train Loss: 0.1491\n",
      "             Validation Loss: 0.2842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 1967/1967 [00:34<00:00, 57.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] - Train Loss: 0.1326\n",
      "             Validation Loss: 0.2892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 1967/1967 [00:47<00:00, 41.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30] - Train Loss: 0.1199\n",
      "             Validation Loss: 0.2604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 1967/1967 [00:47<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30] - Train Loss: 0.1097\n",
      "             Validation Loss: 0.2644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 1967/1967 [00:49<00:00, 39.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30] - Train Loss: 0.1024\n",
      "             Validation Loss: 0.2940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 1967/1967 [00:44<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30] - Train Loss: 0.0967\n",
      "             Validation Loss: 0.2783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 1967/1967 [00:43<00:00, 44.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30] - Train Loss: 0.0902\n",
      "             Validation Loss: 0.2784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 1967/1967 [00:42<00:00, 45.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30] - Train Loss: 0.0848\n",
      "             Validation Loss: 0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 1967/1967 [00:45<00:00, 43.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30] - Train Loss: 0.0818\n",
      "             Validation Loss: 0.2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 1967/1967 [00:44<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30] - Train Loss: 0.0785\n",
      "             Validation Loss: 0.2834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 1967/1967 [00:47<00:00, 41.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30] - Train Loss: 0.0745\n",
      "             Validation Loss: 0.2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 1967/1967 [00:46<00:00, 42.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30] - Train Loss: 0.0715\n",
      "             Validation Loss: 0.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 1967/1967 [00:50<00:00, 38.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30] - Train Loss: 0.0697\n",
      "             Validation Loss: 0.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 1967/1967 [00:49<00:00, 39.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30] - Train Loss: 0.0670\n",
      "             Validation Loss: 0.2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 1967/1967 [00:46<00:00, 42.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30] - Train Loss: 0.0632\n",
      "             Validation Loss: 0.2752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 1967/1967 [00:48<00:00, 40.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30] - Train Loss: 0.0642\n",
      "             Validation Loss: 0.2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 1967/1967 [00:45<00:00, 42.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30] - Train Loss: 0.0601\n",
      "             Validation Loss: 0.2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 1967/1967 [00:49<00:00, 39.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30] - Train Loss: 0.0582\n",
      "             Validation Loss: 0.2809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 1967/1967 [00:48<00:00, 40.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30] - Train Loss: 0.0571\n",
      "             Validation Loss: 0.2808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 1967/1967 [00:46<00:00, 42.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30] - Train Loss: 0.0549\n",
      "             Validation Loss: 0.2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 1967/1967 [00:48<00:00, 40.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30] - Train Loss: 0.0553\n",
      "             Validation Loss: 0.2686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 1967/1967 [00:43<00:00, 44.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30] - Train Loss: 0.0518\n",
      "             Validation Loss: 0.2737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 1967/1967 [00:45<00:00, 43.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30] - Train Loss: 0.0506\n",
      "             Validation Loss: 0.2795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 1967/1967 [00:47<00:00, 41.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30] - Train Loss: 0.0499\n",
      "             Validation Loss: 0.2784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 1967/1967 [00:48<00:00, 40.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30] - Train Loss: 0.0498\n",
      "             Validation Loss: 0.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 1967/1967 [00:48<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30] - Train Loss: 0.0470\n",
      "             Validation Loss: 0.2908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 1967/1967 [00:47<00:00, 41.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30] - Train Loss: 0.0461\n",
      "             Validation Loss: 0.2819\n"
     ]
    }
   ],
   "source": [
    "# ======== ハイパーパラメータ ========\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ======== モデル・損失関数・最適化手法の定義 ========\n",
    "model = TimeSeriesBERTRegressor(input_dim=X_seq_train.shape[2], output_dim=y_seq_train.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# ======== 学習ループ ========\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch, mask_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # デバイスに転送\n",
    "        X_batch = X_batch.to(device)            # [B, S, D]\n",
    "        y_batch = y_batch.to(device)            # [B, output_dim]\n",
    "        mask_batch = mask_batch.to(device)      # [B, S]\n",
    "\n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播\n",
    "        outputs = model(X_batch, attention_mask=mask_batch)  # [B, output_dim]\n",
    "\n",
    "        # 損失計算\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # 逆伝播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ロスの記録\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ======== 検証フェーズ（オプション） ========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val, mask_val in test_loader:\n",
    "            X_val = X_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            mask_val = mask_val.to(device)\n",
    "\n",
    "            outputs = model(X_val, attention_mask=mask_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    print(f\"             Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "# モデル保存\n",
    "torch.save(model.state_dict(), \"weight_BERT/bert_pose_regressor.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8a11d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # テストデータをTensorに変換\n",
    "    sample_input = torch.tensor(X_seq_test, dtype=torch.float32).to(device)       # shape: [N, S, D]\n",
    "    sample_mask = torch.tensor(mask_seq_test, dtype=torch.long).to(device)        # shape: [N, S]\n",
    "\n",
    "    predicted_poses = []\n",
    "\n",
    "    for i in range(sample_input.shape[0]):\n",
    "        input_sequence = sample_input[i:i+1]      # shape: [1, S, D]\n",
    "        input_mask = sample_mask[i:i+1]           # shape: [1, S]\n",
    "        \n",
    "        # BERTに入力 → 出力 shape: [1, output_dim]\n",
    "        predicted_pose = model(input_sequence, attention_mask=input_mask).cpu().numpy()\n",
    "        predicted_poses.append(predicted_pose)\n",
    "\n",
    "    # 出力を結合・逆スケーリング\n",
    "    predicted_pose_original_scale = np.concatenate(predicted_poses, axis=0)\n",
    "    predicted_pose_original_scale = y_scaler.inverse_transform(predicted_pose_original_scale)\n",
    "\n",
    "    # 列名作成（21関節 × x, y, z）\n",
    "    column_names = [f'{i}.{coord}' for i in range(21) for coord in ['x', 'y', 'z']]\n",
    "\n",
    "    # for i in range(21):\n",
    "    #         column_names.extend([f'X.{i * 2 + 1}', f'Y.{i * 2 + 1}', f'Z.{i * 2 + 1}'])\n",
    "    \n",
    "    # CSVとして保存\n",
    "    output_df = pd.DataFrame(predicted_pose_original_scale, columns=column_names)\n",
    "    output_df.to_csv(\"output/BERT_predicted_skeleton.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
