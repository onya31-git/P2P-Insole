{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fd00d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled.shape: (47963, 82)\n",
      "y_train_scaled.shape: (47963, 63)\n",
      "X_seq_train: (47954, 10, 82) y_seq_train: (47954, 63)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 2D-CNN(足圧5x7) + 1D-CNN(IMU) → Transformer → 回帰\n",
    "# 学習・検証・保存・推論まで\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) 共通設定\n",
    "# =========================\n",
    "WINDOW_SIZE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LR = 3e-4\n",
    "PRESSURE_COLS = [f'P{i}' for i in range(1, 36)]   # 35チャンネル\n",
    "IMU_COLS = ['Gyro_x','Gyro_y','Gyro_z','Acc_x','Acc_y','Acc_z']\n",
    "PRESSURE_SHAPE = (5, 7)     # P1..P5が1行目, 行優先で並んでいる前提\n",
    "OUT_CSV = \"output/2DCNNTrans_predicted_skeleton.csv\"\n",
    "WEIGHT_PATH = \"weight/2dcnn_trans_pose_regressor.pth\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) データ読み込み（既存のあなたの前処理と整合）\n",
    "#    ここは質問に貼っていただいたコードのロジックを踏襲\n",
    "# =========================\n",
    "# 学習データのペア（そのまま流用）\n",
    "data_pairs = [\n",
    "    ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 03.06.59 PM.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_152700_left.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_152700_right.csv'),\n",
    "    ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 03.45.00 PM.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_160501_left.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_160501_right.csv'),\n",
    "    ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 04.28.00 PM.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_164800_left.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_164800_right.csv'),\n",
    "    ('./data/20250517old_data/20241212test4/Opti-track/Take 2024-12-12 05.17.59 PM.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_173800_left.csv',\n",
    "     './data/20250517old_data/20241212test4/insoleSensor/20241212_173800_right.csv')\n",
    "]\n",
    "\n",
    "# テストデータ（そのまま流用）\n",
    "test_data = ('./data/20250517old_data/20241115test3/Opti-track/Take 2024-11-15 03.50.00 PM.csv', \n",
    "              './data/20250517old_data/20241115test3/insoleSensor/20241115_155500_left.csv', \n",
    "              './data/20250517old_data/20241115test3/insoleSensor/20241115_155500_right.csv')\n",
    "\n",
    "# 学習セット作成（左右CSVを横結合して1つの特徴行列に）\n",
    "X_train_list, y_train_list = [], []\n",
    "for opti_path, left_path, right_path in data_pairs:\n",
    "    left_df = pd.read_csv(left_path).fillna(0.0)\n",
    "    right_df = pd.read_csv(right_path).fillna(0.0)\n",
    "    y_df = pd.read_csv(opti_path).fillna(0.0)\n",
    "\n",
    "    # 時間長を揃える\n",
    "    T = min(len(left_df), len(right_df), len(y_df))\n",
    "    left_df = left_df.iloc[:T]\n",
    "    right_df = right_df.iloc[:T]\n",
    "    y_df = y_df.iloc[:T]\n",
    "\n",
    "    X_df = pd.concat([left_df, right_df], axis=1)\n",
    "\n",
    "    X_train_list.append(X_df.values)\n",
    "    y_train_list.append(y_df.values)\n",
    "\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "\n",
    "# スケーリング\n",
    "x_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "\n",
    "print(\"X_train_scaled.shape:\", X_train_scaled.shape)\n",
    "print(\"y_train_scaled.shape:\", y_train_scaled.shape)\n",
    "\n",
    "# テスト読み込み\n",
    "opti_path_test, left_path_test, right_path_test = test_data\n",
    "left_df_test = pd.read_csv(left_path_test).fillna(0.0)\n",
    "right_df_test = pd.read_csv(right_path_test).fillna(0.0)\n",
    "y_df_test = pd.read_csv(opti_path_test).fillna(0.0)\n",
    "\n",
    "Tt = min(len(left_df_test), len(right_df_test), len(y_df_test))\n",
    "left_df_test = left_df_test.iloc[:Tt]\n",
    "right_df_test = right_df_test.iloc[:Tt]\n",
    "y_df_test = y_df_test.iloc[:Tt]\n",
    "\n",
    "X_test = pd.concat([left_df_test, right_df_test], axis=1).values\n",
    "y_test = y_df_test.values\n",
    "\n",
    "X_test_scaled = x_scaler.transform(X_test)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "# =========================\n",
    "# 2) スライディング窓（X全体を窓切り）\n",
    "#    ここでは X の列のうち:\n",
    "#    - 先頭35列を足圧5x7\n",
    "#    - 末尾6列をIMU\n",
    "#    とみなす実装にしています。\n",
    "#    列順が違う場合は適宜抽出方法を変えてください。\n",
    "# =========================\n",
    "def create_sliding_window_sequences(X, y, window_size):\n",
    "    X_seq, y_seq, mask_seq = [], [], []\n",
    "    N = len(X)\n",
    "    for i in range(N - window_size + 1):\n",
    "        xw = X[i:i+window_size]\n",
    "        yw = y[i+window_size-1]   # 末尾フレームの姿勢を回帰\n",
    "        mw = np.ones((window_size,), dtype=np.int64)  # 欠損対応するなら修正\n",
    "\n",
    "        X_seq.append(xw)\n",
    "        y_seq.append(yw)\n",
    "        mask_seq.append(mw)\n",
    "    return np.array(X_seq), np.array(y_seq), np.array(mask_seq)\n",
    "\n",
    "X_seq_train, y_seq_train, mask_seq_train = create_sliding_window_sequences(\n",
    "    X_train_scaled, y_train_scaled, WINDOW_SIZE\n",
    ")\n",
    "X_seq_test, y_seq_test, mask_seq_test = create_sliding_window_sequences(\n",
    "    X_test_scaled, y_test_scaled, WINDOW_SIZE\n",
    ")\n",
    "\n",
    "print(\"X_seq_train:\", X_seq_train.shape, \"y_seq_train:\", y_seq_train.shape)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Dataset\n",
    "#    Dataset内で [B,S,D] → 足圧2D + IMU に分割\n",
    "# =========================\n",
    "class PostureDataset2D(Dataset):\n",
    "    def __init__(self, X_seq, y_seq, mask_seq, press_dim=35, imu_dim=6, grid_hw=(5,7)):\n",
    "        self.X = torch.tensor(X_seq, dtype=torch.float32)      # [B,S,D]\n",
    "        self.y = torch.tensor(y_seq, dtype=torch.float32)      # [B,out_dim]\n",
    "        self.m = torch.tensor(mask_seq, dtype=torch.long)      # [B,S]\n",
    "        self.press_dim = press_dim\n",
    "        self.imu_dim = imu_dim\n",
    "        self.H, self.W = grid_hw\n",
    "        assert self.press_dim == self.H*self.W, \"PRESSURE_SHAPEとP列数が一致しません\"\n",
    "\n",
    "        D = self.X.shape[2]\n",
    "        assert D >= (press_dim + imu_dim), \"特徴次元が不足しています\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]           # [S, D]\n",
    "        y = self.y[idx]\n",
    "        m = self.m[idx]           # [S]\n",
    "\n",
    "        # [S, press_dim] と [S, imu_dim] に切り分け\n",
    "        press = x[:, :self.press_dim]             # [S, 35]\n",
    "        imu = x[:, -self.imu_dim:]                # [S, 6]\n",
    "\n",
    "        # 2D reshape → [S, 1, H, W]\n",
    "        press = press.reshape(-1, 1, self.H, self.W)\n",
    "\n",
    "        return press, imu, y, m\n",
    "\n",
    "\n",
    "train_ds = PostureDataset2D(X_seq_train, y_seq_train, mask_seq_train,\n",
    "                            press_dim=35, imu_dim=6, grid_hw=PRESSURE_SHAPE)\n",
    "test_ds  = PostureDataset2D(X_seq_test, y_seq_test, mask_seq_test,\n",
    "                            press_dim=35, imu_dim=6, grid_hw=PRESSURE_SHAPE)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc899972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\20250415P2P-Insole\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "Train 1/30: 100%|██████████| 375/375 [00:07<00:00, 47.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] Train 0.57609 | Val 1.50263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2/30: 100%|██████████| 375/375 [00:07<00:00, 48.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 02] Train 0.32793 | Val 1.53029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3/30: 100%|██████████| 375/375 [00:07<00:00, 48.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 03] Train 0.24561 | Val 1.30728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4/30: 100%|██████████| 375/375 [00:07<00:00, 48.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 04] Train 0.20466 | Val 1.42405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5/30: 100%|██████████| 375/375 [00:07<00:00, 48.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 05] Train 0.17218 | Val 1.56545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6/30: 100%|██████████| 375/375 [00:07<00:00, 49.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 06] Train 0.15160 | Val 1.30964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7/30: 100%|██████████| 375/375 [00:07<00:00, 48.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 07] Train 0.13407 | Val 1.51664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8/30: 100%|██████████| 375/375 [00:07<00:00, 49.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 08] Train 0.12344 | Val 1.44438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9/30: 100%|██████████| 375/375 [00:07<00:00, 48.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 09] Train 0.11159 | Val 1.46569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 10/30: 100%|██████████| 375/375 [00:07<00:00, 48.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train 0.10192 | Val 1.44488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 11/30: 100%|██████████| 375/375 [00:07<00:00, 48.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train 0.09412 | Val 1.45045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 12/30: 100%|██████████| 375/375 [00:07<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train 0.08866 | Val 1.51036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 13/30: 100%|██████████| 375/375 [00:07<00:00, 48.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train 0.08202 | Val 1.49408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 14/30: 100%|██████████| 375/375 [00:07<00:00, 48.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train 0.07655 | Val 1.43623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 15/30: 100%|██████████| 375/375 [00:07<00:00, 47.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train 0.07124 | Val 1.46637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 16/30: 100%|██████████| 375/375 [00:07<00:00, 47.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train 0.06727 | Val 1.42822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 17/30: 100%|██████████| 375/375 [00:07<00:00, 47.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train 0.06274 | Val 1.51052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 18/30: 100%|██████████| 375/375 [00:07<00:00, 47.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train 0.05933 | Val 1.46984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 19/30: 100%|██████████| 375/375 [00:07<00:00, 48.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train 0.05578 | Val 1.45888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 20/30: 100%|██████████| 375/375 [00:07<00:00, 47.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train 0.05402 | Val 1.45265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 21/30: 100%|██████████| 375/375 [00:07<00:00, 48.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train 0.05027 | Val 1.46845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 22/30: 100%|██████████| 375/375 [00:07<00:00, 48.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train 0.04775 | Val 1.46641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 23/30: 100%|██████████| 375/375 [00:07<00:00, 48.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train 0.04595 | Val 1.43773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 24/30: 100%|██████████| 375/375 [00:07<00:00, 47.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train 0.04435 | Val 1.49703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 25/30: 100%|██████████| 375/375 [00:07<00:00, 47.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train 0.04314 | Val 1.46717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 26/30: 100%|██████████| 375/375 [00:07<00:00, 47.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train 0.04212 | Val 1.46491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 27/30: 100%|██████████| 375/375 [00:07<00:00, 47.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train 0.04165 | Val 1.47389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 28/30: 100%|██████████| 375/375 [00:07<00:00, 47.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train 0.04094 | Val 1.46967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 29/30: 100%|██████████| 375/375 [00:07<00:00, 48.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train 0.04060 | Val 1.47226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 30/30: 100%|██████████| 375/375 [00:07<00:00, 47.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train 0.04025 | Val 1.47249\n",
      "Saved weights: weight/2dcnn_trans_pose_regressor.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 4) モデル\n",
    "# =========================\n",
    "class PressureCNN2D(nn.Module):\n",
    "    \"\"\" 時刻ごとの 1×H×W マップを2D-CNNで埋め込みに圧縮 \"\"\"\n",
    "    def __init__(self, out_dim=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # 入力チャネル1\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))  # [B*S,64,1,1]\n",
    "        )\n",
    "        self.fc = nn.Linear(64, out_dim)\n",
    "\n",
    "    def forward(self, press_seq):\n",
    "        # press_seq: [B,S,1,H,W]\n",
    "        B, S, C, H, W = press_seq.shape\n",
    "        x = press_seq.reshape(B*S, C, H, W)\n",
    "        h = self.net(x).reshape(B*S, -1)         # [B*S, 64]\n",
    "        h = self.fc(h)                            # [B*S, out_dim]\n",
    "        return h.reshape(B, S, -1)                # [B,S,out_dim]\n",
    "\n",
    "\n",
    "class IMUCNN1D(nn.Module):\n",
    "    \"\"\" IMUの短時間特徴（1D-CNN） \"\"\"\n",
    "    def __init__(self, in_dim=6, out_dim=256, k=5, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_dim, 128, kernel_size=k, padding=k//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, out_dim, kernel_size=k, padding=k//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(out_dim, out_dim, kernel_size=k, padding=k//2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, imu_seq):\n",
    "        # imu_seq: [B,S,D]\n",
    "        x = imu_seq.transpose(1, 2)          # [B,D,S]\n",
    "        h = self.net(x).transpose(1, 2)      # [B,S,out_dim]\n",
    "        return h\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=20000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float()\n",
    "                        * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)[:, :pe[:,0::2].shape[1]]\n",
    "        pe[:, 1::2] = torch.cos(pos * div)[:, :pe[:,1::2].shape[1]]\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # [1,L,D]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class CNN2DTransformerRegressor(nn.Module):\n",
    "    def __init__(self, d_cnn=256, d_model=512, nhead=8, num_layers=6,\n",
    "                 dim_ff=1024, dropout=0.1, out_dim=63):\n",
    "        super().__init__()\n",
    "        self.cnn2d = PressureCNN2D(out_dim=d_cnn, dropout=dropout)\n",
    "        self.cnn1d = IMUCNN1D(in_dim=6, out_dim=d_cnn, dropout=dropout)\n",
    "\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Linear(d_cnn*2, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.posenc = PositionalEncoding(d_model)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_ff,\n",
    "            dropout=dropout, activation='gelu',\n",
    "            batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, out_dim)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def last_valid_token(h, mask):\n",
    "        lengths = mask.sum(dim=1)\n",
    "        idx = torch.clamp(lengths - 1, min=0)\n",
    "        b = torch.arange(h.size(0), device=h.device)\n",
    "        return h[b, idx, :]\n",
    "\n",
    "    def forward(self, press_seq, imu_seq, mask):\n",
    "        # press_seq: [B,S,1,H,W], imu_seq: [B,S,6], mask: [B,S]\n",
    "        hp = self.cnn2d(press_seq)   # [B,S,d_cnn]\n",
    "        hi = self.cnn1d(imu_seq)     # [B,S,d_cnn]\n",
    "        h = torch.cat([hp, hi], dim=-1)\n",
    "        h = self.fuse(h)\n",
    "        h = self.posenc(h)\n",
    "\n",
    "        pad_mask = (mask == 0)\n",
    "        h = self.encoder(h, src_key_padding_mask=pad_mask)\n",
    "\n",
    "        cls = self.last_valid_token(h, mask)\n",
    "        yhat = self.head(cls)\n",
    "        return yhat\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) 学習\n",
    "# =========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = y_seq_train.shape[1]\n",
    "model = CNN2DTransformerRegressor(\n",
    "    d_cnn=256, d_model=512, nhead=8, num_layers=6,\n",
    "    dim_ff=1024, dropout=0.1, out_dim=out_dim\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for press, imu, y, m in tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\"):\n",
    "        press = press.to(device)   # [B,S,1,H,W]\n",
    "        imu   = imu.to(device)     # [B,S,6]\n",
    "        y     = y.to(device)       # [B,out_dim]\n",
    "        m     = m.to(device)       # [B,S]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(press, imu, m)\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "    scheduler.step()\n",
    "    train_loss = total / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for press, imu, y, m in test_loader:\n",
    "            press = press.to(device)\n",
    "            imu   = imu.to(device)\n",
    "            y     = y.to(device)\n",
    "            m     = m.to(device)\n",
    "            yhat = model(press, imu, m)\n",
    "            loss = criterion(yhat, y)\n",
    "            val_total += loss.item()\n",
    "    val_loss = val_total / len(test_loader)\n",
    "\n",
    "    print(f\"[Epoch {epoch:02d}] Train {train_loss:.5f} | Val {val_loss:.5f}\")\n",
    "\n",
    "# 保存\n",
    "os.makedirs(os.path.dirname(WEIGHT_PATH), exist_ok=True)\n",
    "torch.save(model.state_dict(), WEIGHT_PATH)\n",
    "print(\"Saved weights:\", WEIGHT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d99d523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output/2DCNNTrans_predicted_skeleton.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 6) 推論\n",
    "# =========================\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for press, imu, _, m in test_loader:\n",
    "        press = press.to(device)\n",
    "        imu   = imu.to(device)\n",
    "        m     = m.to(device)\n",
    "        yhat  = model(press, imu, m)\n",
    "        preds.append(yhat.cpu().numpy())\n",
    "\n",
    "pred_scaled = np.concatenate(preds, axis=0)\n",
    "pred = y_scaler.inverse_transform(pred_scaled)\n",
    "\n",
    "J = pred.shape[1] // 3\n",
    "cols = [f'{ax}.{j*2 +1}' for j in range(J) for ax in ['X','Y','Z']]\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "pd.DataFrame(pred, columns=cols).to_csv(OUT_CSV, index=False)\n",
    "print(\"Saved:\", OUT_CSV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
